{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4d6f26-5a4d-47de-91be-92fba7ebaa43",
   "metadata": {},
   "source": [
    "1) Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb1f82-fbc5-47be-87d0-042b861808bd",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to test for significant differences among means of two or more groups. In order to use ANOVA, several assumptions must be met. Violations of these assumptions can lead to inaccurate or invalid results.\n",
    "\n",
    "The assumptions required for ANOVA are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579804f7-8b1a-4b5c-b1a3-643717604ff2",
   "metadata": {},
   "source": [
    "1) Normality : The data in each group should follow a normal distribution\n",
    "2) Homogenity of variance : The variance of the data in each group should be approximately equal\n",
    "3) Independence : The observations in each group should be independent of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54591b48-214f-4ee5-a174-a76c962a222f",
   "metadata": {},
   "source": [
    "ex:\n",
    "1) Violation of normality assumption: If the data in each group are not normally distributed, ANOVA may not be valid. For example, if the data are skewed or have outliers, the normality assumption may be violated. In such cases, non-parametric tests like the Kruskal-Wallis test may be used instead\n",
    "2) Violation of homogeneity of variance assumption: If the variance of the data in each group is not approximately equal, ANOVA may not be valid. For example, if the data in one group have a much larger variance than the others, this assumption may be violated. In such cases, Welch's ANOVA or a non-parametric alternative may be used\n",
    "3) Violation of independence assumption: If the observations in each group are not independent of each other, ANOVA may not be valid. For example, if the same participant is measured in multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6bad3-b86f-48ae-ba32-893ef15386bf",
   "metadata": {},
   "source": [
    "2) What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa14053-640f-4c7a-a90d-e1be89d32333",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to analyze the differences between two or more groups. There are three types of ANOVA\n",
    "\n",
    "1) One-way ANOVA : One-way ANOVA is used when you want to compare the means of three or more groups for a single independent variable. For example, if you want to compare the average income of people from different countries, you can use one-way ANOVA\n",
    "2) Two-way ANOVA : Two-way ANOVA is used when you want to compare the means of two or more groups for two independent variables. For example, if you want to compare the average income of people from different countries based on their gender, you can use two-way ANOVA\n",
    "3) Mixed-way ANOVA : Mixed ANOVA is used when you want to compare the means of two or more groups for both within-subjects and between-subjects factors. For example, if you want to compare the effect of a drug on two groups of people, with one group receiving the drug and the other receiving a placebo, and you want to measure the effect at different time points, you can use mixed ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c04c3-850f-4c10-b782-3413160d5e6f",
   "metadata": {},
   "source": [
    "Each type of ANOVA is used in different situations, depending on the number of independent variables and the type of design of the study. One-way ANOVA is used when there is one independent variable and the groups are independent. Two-way ANOVA is used when there are two independent variables and the groups are independent. Mixed ANOVA is used when there are both within-subjects and between-subjects factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04411be-60ea-438e-bd41-c35848cf774e",
   "metadata": {},
   "source": [
    "3) What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a528d-2052-4388-9ffd-ee9501101e95",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA (Analysis of Variance) refers to the process of decomposing the total variation in a data set into its component parts, which can be attributed to different sources of variation. In ANOVA, the total variation in the dependent variable is partitioned into two or more components: the variation due to differences among the groups being compared and the variation due to random error or individual differences.\n",
    "\n",
    "The partitioning of variance is important because it helps researchers to understand the relative contributions of different sources of variation to the overall variation in their data, and to determine whether the treatment effect is statistically significant. By partitioning the total variation in a data set into its component parts, researchers can determine the proportion of the total variation that is accounted for by the treatment effect, as well as the proportion that is due to chance or individual differences\n",
    "\n",
    "Understanding the partitioning of variance is also important because it allows researchers to calculate effect sizes, which are measures of the strength of the relationship between the independent and dependent variables. Effect sizes are important because they provide a more meaningful interpretation of the results of statistical analyses than p-values alone, and they can be used to compare the strength of the treatment effect across different studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4783b81-33c6-4d6e-9597-7b6904c0e20c",
   "metadata": {},
   "source": [
    "4) How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b5df8-a20d-4f8c-a030-136737616c08",
   "metadata": {},
   "source": [
    "To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can use the statsmodels library.\n",
    "\n",
    "First, you need to import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a99742-ff32-4cd2-afe9-86af0cb187ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 16.0\n",
      "SSR: 1.5\n",
      "SST: 17.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = {'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "        'value': [1, 2, 3, 4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "model = ols('value ~ group', data=df).fit()\n",
    "ssr = model.ssr\n",
    "sse = model.ess\n",
    "sst = sse + ssr\n",
    "\n",
    "print('SSE:', sse)\n",
    "print('SSR:', ssr)\n",
    "print('SST:', sst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb80a00-31b6-4c4b-96ea-cb517e46885f",
   "metadata": {},
   "source": [
    "5) In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19740e0-5c6c-4bd7-9e9c-990562ea8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = pd.read_csv('mydata.csv')\n",
    "model = ols('outcome_var ~ var1 + var2 + var1*var2', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "print(table)\n",
    "main_effect_var1 = model.params['var1']\n",
    "main_effect_var2 = model.params['var2']\n",
    "interaction_effect = model.params['var1:var2']\n",
    "print('Main effect of var1:', main_effect_var1)\n",
    "print('Main effect of var2:', main_effect_var2)\n",
    "print('Interaction effect:', interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083517f-d537-401c-a00e-c44e5c93190e",
   "metadata": {},
   "source": [
    "6) Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d622a-ed24-4786-bba3-d9c8fdc0b78e",
   "metadata": {},
   "source": [
    "If you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there is evidence to suggest that there are significant differences between the groups in the population from which the samples were drawn.\n",
    "\n",
    "The F-statistic is a measure of the ratio of variance between the groups and variance within the groups. A larger F-statistic value suggests that there is more variability between the groups, which may indicate that there are significant differences between them. The p-value of 0.02 indicates that there is a low probability (2%) of observing such an F-statistic if there were no significant differences between the groups in the population.\n",
    "\n",
    "Therefore, we can reject the null hypothesis that there are no significant differences between the groups, and conclude that at least one of the groups is significantly different from the others. However, we cannot determine which specific group(s) is different from the others without further analysis.\n",
    "\n",
    "In terms of interpretation, these results suggest that there are differences in the means of the groups, but we cannot determine the nature or magnitude of these differences without further analysis. Additionally, the significance of the differences depends on the context and the goals of the study, and it may be necessary to conduct post-hoc tests or further analysis to fully understand the implications of these findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a3f1d-3104-4c84-a187-7bc6cd10b009",
   "metadata": {},
   "source": [
    "7) In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19650d-ac23-44ea-af53-d73a4a945c74",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA can be a challenging task since the data are correlated across time points and within-subjects, and ignoring the missing data can lead to biased estimates and reduced statistical power. Here are a few common methods to handle missing data in a repeated measures ANOVA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c225e-b882-4f76-909b-4e216598087c",
   "metadata": {},
   "source": [
    "1) Complete-case-analysis : In this approach, only complete cases (i.e., subjects with data at all time points) are included in the analysis, and missing data are simply excluded. While this method is straightforward and easy to implement, it can lead to biased results if the missing data are not missing completely at random\n",
    "2) Pairwise deletion : In this approach, only the available data at each time point are used for each subject, and missing data are replaced by a mean or a median of the observed data for that subject. While this method allows for more subjects to be included in the analysis, it can lead to biased results if the missing data are not MCAR\n",
    "3) Multiple imputation : In this approach, missing data are imputed multiple times to create several completed datasets, which are then analyzed separately, and the results are combined. This method can provide more accurate estimates and preserve statistical power, especially if the missing data are missing at random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15144b4f-1dcb-4109-b9bd-e98c8f2c0c12",
   "metadata": {},
   "source": [
    "The consequences of using different methods to handle missing data in a repeated measures ANOVA can be significant. Using complete-case analysis or pairwise deletion can lead to biased results and reduced statistical power, especially if the missing data are not MCAR. Multiple imputation can provide more accurate estimates and preserve statistical power, but it can be computationally intensive and requires assumptions about the missing data mechanism. The choice of method should depend on the characteristics of the missing data and the goals of the analysis, and it is recommended to conduct sensitivity analyses to examine the robustness of the results to different methods of handling missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac941a-e3b9-4f53-8ad3-8c040027c963",
   "metadata": {},
   "source": [
    "8) What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaeeed3-eaaf-46b5-a26a-1d5c89782339",
   "metadata": {},
   "source": [
    "Post-hoc tests are used to compare specific pairs of groups after obtaining a significant result in an ANOVA, and they can help identify which groups differ significantly from each other. Here are some common post-hoc tests used after ANOVA, along with their characteristics and situations where they might be used:\n",
    "\n",
    "1) Tukey's Honestly Significant Difference (HSD): This test compares all possible pairs of means while controlling the overall Type I error rate. It is commonly used when the number of groups is small and equal, and when the variances are homogeneous across groups.\n",
    "\n",
    "2) Bonferroni correction: This test adjusts the alpha level for each comparison to control the family-wise error rate. It is commonly used when there are a large number of pairwise comparisons, and when the variances are heterogeneous across groups.\n",
    "\n",
    "3) Scheffe's test: This test adjusts the alpha level based on the number of contrasts being made, which can be useful when testing multiple hypotheses simultaneously. It is commonly used when there are a small number of groups and a large number of contrasts.\n",
    "\n",
    "4) Games-Howell test: This test does not assume equal variances across groups and can be used when the assumption of equal variances is violated. It is commonly used when the sample sizes are unequal or when the variances are heterogeneous across groups.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is a study that examines the effects of different treatments on a medical condition. Suppose that an ANOVA is used to compare the mean improvement scores of four treatment groups, and the ANOVA result indicates a significant difference among the groups. A post-hoc test can be used to determine which specific pairs of groups differ significantly from each other, which can help identify the most effective treatment(s) for the medical condition. In this case, Tukey's HSD test or Bonferroni correction can be used to compare all possible pairs of means, while controlling the overall Type I error rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c515b4c-0d65-43f8-89bd-c76945e9f66f",
   "metadata": {},
   "source": [
    "9) A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffadc42c-3c3e-4343-9b1f-b20ee48f40c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 205.54449472096522\n",
      "p-value: 1.7337754997814795e-30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "diet_A = np.array([4.5, 5.2, 6.1, 4.9, 5.7, 5.8, 6.2, 4.8, 5.6, 5.0,\n",
    "                   5.9, 6.3, 5.1, 6.0, 5.5, 5.3, 5.4, 4.7, 5.8, 6.4,\n",
    "                   4.6, 5.2, 6.2, 5.9, 5.3])\n",
    "diet_B = np.array([3.9, 3.8, 4.2, 4.5, 3.7, 4.1, 4.3, 3.5, 3.9, 4.0,\n",
    "                   4.2, 4.4, 4.1, 4.6, 4.5, 4.0, 4.3, 4.4, 4.7, 4.2,\n",
    "                   4.1, 4.3, 4.5, 4.7, 4.4])\n",
    "diet_C = np.array([2.8, 3.1, 2.9, 3.3, 3.2, 3.6, 3.0, 3.5, 3.4, 2.9,\n",
    "                   3.2, 3.3, 3.1, 3.5, 3.4, 3.6, 3.0, 3.1, 3.3, 3.5,\n",
    "                   3.2, 3.4, 3.1, 3.6, 3.2])\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "print('F-statistic:', f_statistic)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0f541-2f91-4209-8ef4-e79bd6f8946d",
   "metadata": {},
   "source": [
    "10) A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e99e3e-ffac-43fe-81ea-6231662712be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = pd.DataFrame({\n",
    "    'Program': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "    'Experience': ['Novice']*15 + ['Experienced']*15 + ['Novice']*15 + ['Experienced']*15 + ['Novice']*15 + ['Experienced']*15,\n",
    "    'Time': [32, 29, 31, 28, 33, 30, 31, 27, 30, 28, 33, 29, 30, 31, 28, 27, 34, 29, 33, 30, 31, 32, 28, 29, 30, 32, 31, 30, 29, 28,\n",
    "             35, 37, 38, 36, 39, 36, 35, 37, 38, 36, 39, 37, 36, 38, 36, 35, 40, 38, 39, 37, 36, 35, 37, 38, 36, 38, 39, 37, 36, 35]\n",
    "})\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4485a1-5766-400d-bc97-8c20af3066bc",
   "metadata": {},
   "source": [
    "11) An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673a4a3f-8dfd-4c75-9c72-88a099b24131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -8.13\n",
      "P-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "control_scores = np.array([78, 85, 69, 82, 79, 94, 80, 83, 76, 81, 87, 75, 71, 88, 90, 77, 84, 79, 86, 85, 73, 80, 75, 82, 81, 78, 83, 90, 85, 84, 86, 88, 79, 84, 80, 72, 81, 83, 75, 70, 87, 79, 86, 82, 76, 84, 88, 80, 74, 89, 77, 73, 81, 85, 77, 79, 83, 82, 85, 71, 90, 84, 77, 82, 89, 83, 85, 76, 81, 84, 86, 88, 79, 84, 75, 82, 81, 77, 86, 83, 79, 84, 85, 78, 83, 87, 88, 80, 76, 84, 75, 81, 79, 83, 82, 85, 72, 89, 86, 80, 88, 84, 85, 83, 81, 78])\n",
    "experimental_scores = np.array([92, 81, 76, 91, 85, 87, 94, 90, 82, 86, 79, 92, 88, 86, 85, 95, 83, 86, 90, 94, 80, 89, 84, 91, 78, 86, 84, 92, 85, 88, 83, 94, 89, 87, 80, 81, 90, 83,84, 87, 92, 90, 84, 78, 89, 87, 91, 85, 92, 84, 90, 88, 91, 84, 89, 82, 87, 85, 81, 89, 88, 84, 86, 81, 92, 88, 86, 83, 90, 87, 86, 85, 90, 89, 88, 81, 91, 85, 83, 88, 92, 88, 86, 83, 91, 85, 87, 89, 86, 82, 80, 92, 87, 83, 85, 90, 91, 80, 89, 85, 91, 88, 92])\n",
    "t_stat, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "print(f\"T-statistic: {t_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9cf46-7de8-445d-8075-ec32e076a8e5",
   "metadata": {},
   "source": [
    "12) A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1f937e0-0351-475a-b15e-6c7adbb991e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  sales   R-squared:                       0.863\n",
      "Model:                            OLS   Adj. R-squared:                  0.790\n",
      "Method:                 Least Squares   F-statistic:                     11.79\n",
      "Date:                Thu, 30 Mar 2023   Prob (F-statistic):           1.58e-15\n",
      "Time:                        03:43:03   Log-Likelihood:                -209.10\n",
      "No. Observations:                  90   AIC:                             482.2\n",
      "Df Residuals:                      58   BIC:                             562.2\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         3.2889      1.835      1.792      0.078      -0.384       6.962\n",
      "C(store)[T.B]    -2.1667      0.795     -2.727      0.008      -3.757      -0.576\n",
      "C(store)[T.C]     4.3000      0.795      5.412      0.000       2.709       5.891\n",
      "C(day)[T.2]      -0.3333      2.513     -0.133      0.895      -5.363       4.696\n",
      "C(day)[T.3]       1.6667      2.513      0.663      0.510      -3.363       6.696\n",
      "C(day)[T.4]       3.3333      2.513      1.327      0.190      -1.696       8.363\n",
      "C(day)[T.5]       3.0000      2.513      1.194      0.237      -2.030       8.030\n",
      "C(day)[T.6]       4.0000      2.513      1.592      0.117      -1.030       9.030\n",
      "C(day)[T.7]       5.6667      2.513      2.255      0.028       0.637      10.696\n",
      "C(day)[T.8]       8.3333      2.513      3.316      0.002       3.304      13.363\n",
      "C(day)[T.9]       8.3333      2.513      3.316      0.002       3.304      13.363\n",
      "C(day)[T.10]     10.3333      2.513      4.112      0.000       5.304      15.363\n",
      "C(day)[T.11]     12.0000      2.513      4.776      0.000       6.970      17.030\n",
      "C(day)[T.12]     13.3333      2.513      5.306      0.000       8.304      18.363\n",
      "C(day)[T.13]     15.0000      2.513      5.970      0.000       9.970      20.030\n",
      "C(day)[T.14]     16.6667      2.513      6.633      0.000      11.637      21.696\n",
      "C(day)[T.15]     17.0000      2.513      6.765      0.000      11.970      22.030\n",
      "C(day)[T.16]     17.3333      2.513      6.898      0.000      12.304      22.363\n",
      "C(day)[T.17]     17.6667      2.513      7.031      0.000      12.637      22.696\n",
      "C(day)[T.18]     18.0000      2.513      7.163      0.000      12.970      23.030\n",
      "C(day)[T.19]     17.3333      2.513      6.898      0.000      12.304      22.363\n",
      "C(day)[T.20]     16.0000      2.513      6.368      0.000      10.970      21.030\n",
      "C(day)[T.21]     14.6667      2.513      5.837      0.000       9.637      19.696\n",
      "C(day)[T.22]     13.6667      2.513      5.439      0.000       8.637      18.696\n",
      "C(day)[T.23]     12.3333      2.513      4.908      0.000       7.304      17.363\n",
      "C(day)[T.24]     11.3333      2.513      4.510      0.000       6.304      16.363\n",
      "C(day)[T.25]     10.0000      2.513      3.980      0.000       4.970      15.030\n",
      "C(day)[T.26]      9.0000      2.513      3.582      0.001       3.970      14.030\n",
      "C(day)[T.27]      7.6667      2.513      3.051      0.003       2.637      12.696\n",
      "C(day)[T.28]      6.6667      2.513      2.653      0.010       1.637      11.696\n",
      "C(day)[T.29]      5.6667      2.513      2.255      0.028       0.637      10.696\n",
      "C(day)[T.30]      4.6667      2.513      1.857      0.068      -0.363       9.696\n",
      "==============================================================================\n",
      "Omnibus:                       33.324   Durbin-Watson:                   0.107\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                5.729\n",
      "Skew:                           0.046   Prob(JB):                       0.0570\n",
      "Kurtosis:                       1.768   Cond. No.                         34.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "     A      B  -2.1667 0.3716 -5.9933    1.66  False\n",
      "     A      C      4.3 0.0237  0.4733  8.1267   True\n",
      "     B      C   6.4667 0.0003    2.64 10.2933   True\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = {'store': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "        'day': list(range(1,31))*3,\n",
    "        'sales': [4,5,7,8,5,6,9,11,10,12,14,15,16,18,19,20,22,23,21,19,18,17,16,15,14,13,12,11,10,9] +\n",
    "                 [3,2,4,6,7,8,9,12,14,16,17,18,20,22,21,20,18,17,15,14,13,12,10,9,7,6,5,4,3,2] +\n",
    "                 [5,4,6,8,9,10,11,14,13,15,17,19,21,22,23,24,25,26,28,27,25,24,23,22,21,20,18,17,16,15]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "rm_anova = ols('sales ~ C(store) + C(day)', data=df).fit()\n",
    "print(rm_anova.summary())\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "tukey = pairwise_tukeyhsd(df['sales'], df['store'], alpha=0.05)\n",
    "print(tukey.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71293b3-a3f1-46f3-b725-35c165f91ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
